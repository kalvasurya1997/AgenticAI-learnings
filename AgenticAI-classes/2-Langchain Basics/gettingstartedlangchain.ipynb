{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a0281c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1466670",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24aa2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F840D76030> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F840B6C1D0> root_client=<openai.OpenAI object at 0x000001F83F47D1F0> root_async_client=<openai.AsyncOpenAI object at 0x000001F840FA8650> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "llm =ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d110f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**LangChain** is an open-source framework designed to facilitate the development of applications that leverage large language models (LLMs) like OpenAI's GPT series. Created to simplify the integration of LLMs into various applications, LangChain provides a modular and flexible approach, enabling developers to build complex, intelligent systems with ease.\n",
      "\n",
      "### Key Features of LangChain\n",
      "\n",
      "1. **Modular Architecture**:\n",
      "   - **Chains**: LangChain allows you to create sequences of calls and actions, known as \"chains,\" which can process inputs and outputs through multiple steps. This is useful for orchestrating complex workflows involving multiple LLM calls or other actions.\n",
      "   - **Agents**: These are specialized chains that can make decisions based on user input or other data, enabling more interactive and dynamic behaviors within applications.\n",
      "\n",
      "2. **Integration with Multiple LLMs and Tools**:\n",
      "   - LangChain supports integration with various language models, not limited to OpenAI's offerings. This flexibility ensures that developers can choose the best model for their specific use case.\n",
      "   - It also integrates with various data sources, APIs, and other tools, allowing LLMs to interact with external systems seamlessly.\n",
      "\n",
      "3. **Prompt Management**:\n",
      "   - Effective prompt engineering is crucial for leveraging LLMs effectively. LangChain provides utilities to manage, template, and optimize prompts, making it easier to design prompts that yield desired outcomes.\n",
      "\n",
      "4. **Data Handling and Retrieval**:\n",
      "   - The framework includes tools for managing and retrieving data, enabling applications like question-answering systems, where the LLM needs to access and interpret information from databases or documents.\n",
      "\n",
      "5. **Scalability and Performance**:\n",
      "   - Designed with scalability in mind, LangChain supports distributed computing and can handle large-scale deployments, making it suitable for enterprise-level applications.\n",
      "\n",
      "6. **Extensive Documentation and Community Support**:\n",
      "   - Being open-source, LangChain benefits from a growing community of developers who contribute to its development, provide support, and share use cases. Comprehensive documentation helps new users get up to speed quickly.\n",
      "\n",
      "### Common Use Cases\n",
      "\n",
      "- **Chatbots and Conversational Agents**: Building intelligent chatbots that can handle complex conversations, understand context, and provide relevant responses.\n",
      "  \n",
      "- **Automated Content Generation**: Creating tools that generate articles, summaries, reports, or other forms of content based on specific inputs or data.\n",
      "\n",
      "- **Question-Answering Systems**: Developing systems that can retrieve and process information from various sources to answer user queries accurately.\n",
      "\n",
      "- **Data Analysis and Interpretation**: Utilizing LLMs to analyze data, generate insights, and create reports based on data processing.\n",
      "\n",
      "- **Interactive Applications**: Building applications that require natural language understanding and generation, such as virtual assistants or personalized recommendation systems.\n",
      "\n",
      "### Getting Started with LangChain\n",
      "\n",
      "To begin using LangChain, you typically need to:\n",
      "\n",
      "1. **Install the Framework**:\n",
      "   ```bash\n",
      "   pip install langchain\n",
      "   ```\n",
      "\n",
      "2. **Integrate with an LLM**:\n",
      "   Choose and set up a language model provider (e.g., OpenAI, Hugging Face).\n",
      "\n",
      "3. **Build Chains or Agents**:\n",
      "   Define the workflow or the decision-making processes your application requires.\n",
      "\n",
      "4. **Manage Prompts and Data**:\n",
      "   Design effective prompts and set up data retrieval mechanisms as needed for your application.\n",
      "\n",
      "5. **Deploy and Scale**:\n",
      "   Use LangChain's tools and best practices to deploy your application, ensuring it can handle the expected load and performance requirements.\n",
      "\n",
      "### Resources\n",
      "\n",
      "- **Official Website**: [LangChain](https://langchain.com/)\n",
      "- **GitHub Repository**: [github.com/hwchase17/langchain](https://github.com/hwchase17/langchain)\n",
      "- **Documentation**: Comprehensive guides and API references are available on the official website and GitHub repository.\n",
      "- **Community Forums and Discussions**: Engage with other developers and contributors through forums, Slack channels, or Discord servers linked from the official resources.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "LangChain serves as a powerful tool for developers looking to harness the capabilities of large language models within their applications. Its modular design, extensive feature set, and active community support make it a valuable framework for building intelligent, language-aware applications across various industries and use cases.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\"what is langchain?\"])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d78bad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed to facilitate the development of applications powered by large language models (LLMs) like OpenAI's GPT series. It provides a structured approach to building complex, language-driven applications by offering modular components and integrations that handle various aspects of working with LLMs. Here's a detailed overview of what LangChain is and what it offers:\n",
      "\n",
      "### **Key Features of LangChain**\n",
      "\n",
      "1. **Modular Architecture:**\n",
      "   - **Chains:** LangChain introduces the concept of \"chains,\" which are sequences of calls that can be linked together to perform complex tasks. Chains can consist of multiple steps, including input processing, model inference, and output handling.\n",
      "   - **Agents:** These are more dynamic chains that can make decisions about which actions to take based on user input and the current context. Agents can interact with external tools or APIs to fetch data, perform calculations, or execute commands.\n",
      "\n",
      "2. **Prompt Management:**\n",
      "   - **Templates:** LangChain provides tools to create and manage prompt templates, making it easier to standardize and reuse prompts across different parts of an application.\n",
      "   - **Dynamic Prompting:** It supports dynamic modifications of prompts based on user input or other runtime information, allowing for more adaptable and context-aware interactions.\n",
      "\n",
      "3. **Integration with External Data Sources:**\n",
      "   - LangChain can connect to various data sources such as databases, APIs, and document stores. This allows language models to access and incorporate real-time data into their responses, enhancing the relevance and accuracy of the output.\n",
      "\n",
      "4. **Memory Management:**\n",
      "   - **Contextual Memory:** LangChain allows applications to retain context across multiple interactions, enabling more coherent and contextually aware conversations or processes.\n",
      "   - **State Management:** It provides mechanisms to manage the state of interactions, which is particularly useful for multi-turn dialogues or complex workflows.\n",
      "\n",
      "5. **Tool and API Integration:**\n",
      "   - LangChain can interface with a wide range of tools and APIs, enabling language models to perform tasks beyond text generation, such as executing code, retrieving information, or manipulating data.\n",
      "\n",
      "6. **Utilities for Common Tasks:**\n",
      "   - **Text Splitting:** Efficiently breaks down large texts into manageable chunks for processing.\n",
      "   - **Document Retrieval:** Facilitates the retrieval of relevant documents or data based on queries.\n",
      "   - **Semantic Search:** Implements search mechanisms that understand the meaning behind queries to find the most pertinent information.\n",
      "\n",
      "### **Use Cases**\n",
      "\n",
      "LangChain is versatile and can be applied to various domains, including but not limited to:\n",
      "\n",
      "- **Chatbots and Virtual Assistants:** Creating conversational agents that can handle complex dialogues and perform tasks based on user instructions.\n",
      "- **Content Generation:** Automating the creation of articles, summaries, reports, and other forms of written content.\n",
      "- **Data Analysis:** Assisting in interpreting and analyzing large datasets by generating insights and visualizations.\n",
      "- **Automation Tasks:** Streamlining workflows by integrating language models with other software tools and services.\n",
      "- **Educational Tools:** Building applications that aid in learning and tutoring by providing explanations, answering questions, and generating educational content.\n",
      "\n",
      "### **Why Use LangChain?**\n",
      "\n",
      "- **Simplifies Complexity:** By providing a structured framework, LangChain reduces the complexity involved in integrating and orchestrating multiple components required for advanced language-based applications.\n",
      "- **Extensibility:** Its modular design allows developers to easily add or modify components to fit specific needs.\n",
      "- **Community and Support:** Being open-source, LangChain benefits from community contributions, comprehensive documentation, and ongoing support, making it easier to adopt and troubleshoot.\n",
      "\n",
      "### **Getting Started**\n",
      "\n",
      "To start using LangChain, you can install it via pip:\n",
      "\n",
      "```bash\n",
      "pip install langchain\n",
      "```\n",
      "\n",
      "After installation, you can begin building applications by leveraging its various modules and following the examples provided in the [LangChain documentation](https://langchain.com/docs/).\n",
      "\n",
      "### **Conclusion**\n",
      "\n",
      "LangChain stands out as a powerful tool for developers looking to harness the capabilities of large language models in a structured and efficient manner. Its comprehensive set of features and integrations make it easier to build sophisticated, language-driven applications across a wide range of industries and use cases.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "response = llm.invoke([HumanMessage(content=\"What is langchain?\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06d0df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an Expert AI Engineer and provide answers based on the question asked.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##prompt engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an Expert AI Engineer and provide answers based on the question asked.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420e5d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F84737A690>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F84739BFB0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm_model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cda899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an Expert AI Engineer and provide answers based on the question asked.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F84737A690>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F84739BFB0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=prompt|llm_model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ea66f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). \n",
      "\n",
      "Think of it as a toolbox specifically built for working with LLMs like GPT-3, Jurassic-1 Jumbo, or even your own custom models. \n",
      "\n",
      "Here's a breakdown of what makes LangChain so useful:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Modular Components:** LangChain breaks down the process of building LLM applications into reusable components. You have tools for:\n",
      "    *  **Prompt Engineering:** Crafting effective prompts to get the desired output from your LLM.\n",
      "    *  **Memory:**  Giving your applications a \"memory\" so they can remember past interactions and context.\n",
      "    *  **Chains:**  Linking together multiple LLMs or other tools (like search engines or APIs) to create complex workflows.\n",
      "    *  **Agents:**  Building autonomous agents that can interact with the world by making decisions and taking actions based on LLM outputs.\n",
      "\n",
      "* **Integration:** LangChain integrates seamlessly with popular LLMs through various adapters. It also connects with other tools and services, expanding the capabilities of your applications.\n",
      "\n",
      "* **Flexibility:**  LangChain is designed to be highly adaptable. You can customize its components, build your own, and tailor it to your specific application needs.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "LangChain empowers developers to build a wide range of LLM-powered applications, including:\n",
      "\n",
      "* **Chatbots:** Create more intelligent and engaging chatbots with context awareness and personalized responses.\n",
      "* **Question Answering Systems:** Build systems that can accurately answer questions based on a given set of documents or knowledge bases.\n",
      "* **Text Summarization:**  Generate concise summaries of large amounts of text.\n",
      "* **Code Generation:** Assist developers in writing code snippets or even entire programs.\n",
      "* **Workflow Automation:** Automate tasks by combining LLMs with other tools and APIs.\n",
      "\n",
      "**In essence, LangChain provides the infrastructure and tools to unlock the full potential of LLMs, making it easier for developers to build innovative and powerful applications.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"What is langchain?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec1fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). \n",
      "\n",
      "Think of LangChain as a toolbox packed with components specifically crafted to help you build with LLMs. It goes beyond just using an LLM to generate text; it provides the infrastructure to create sophisticated applications that leverage LLMs in various ways.\n",
      "\n",
      "Here's a breakdown of what LangChain offers:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Chain Creation:**  LangChain excels at building \"chains\" of LLM calls. Imagine a multi-step process, like summarizing a document, answering questions about it, and then translating the summary. LangChain lets you chain these LLM calls together seamlessly.\n",
      "* **Memory Management:**  LLMs have limited memory, meaning they \"forget\" past interactions. LangChain provides tools to manage this, allowing your applications to retain context across multiple turns of conversation or steps in a process.\n",
      "* **Data Access:** LangChain makes it easy to connect LLMs to external data sources like databases, APIs, and files. This empowers your applications to access and process real-world information, going beyond just generating text based on pre-existing knowledge.\n",
      "* **Agents:** LangChain enables you to build autonomous agents that can interact with the world. These agents can combine LLMs with other tools and services to accomplish complex tasks, such as scheduling meetings, booking flights, or even playing games.\n",
      "* **Prompt Engineering Tools:**  Crafting effective prompts is crucial for getting good results from LLMs. LangChain offers utilities and templates to help you design and refine your prompts.\n",
      "\n",
      "**In essence, LangChain acts as a bridge between the power of LLMs and the real world, enabling you to build more sophisticated, context-aware, and capable applications.**\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about LangChain or want to explore specific aspects in more detail!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=  prompt|llm_model|output_parser\n",
    "response=chain.invoke({\"input\":\"What is langchain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edea9aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'LangChain is a framework for developing applications powered by language models.'}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Output parser\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "# Prompt with escaped curly braces\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\", \n",
    "        'You are a helpful assistant. Respond ONLY in valid JSON like this: {{\"answer\": \"your answer\"}}'\n",
    "    ),\n",
    "    (\n",
    "        \"human\", \n",
    "        \"{input}\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# Chain it all together\n",
    "chain = prompt | llm_model | output_parser\n",
    "\n",
    "# Invoke the chain\n",
    "response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f99983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response><answer>LangChain is a framework for developing applications powered by large language models (LLMs). It provides tools and components to simplify the process of building and deploying LLM-based applications, such as chatbots, question-answering systems, and text summarizers.</answer></response>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "#chain = prompt | llm_model | output_parser\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output = (prompt | llm_model).invoke({\"input\": \"What is LangChain?\"})\n",
    "print(raw_output.content)\n",
    "\n",
    "# Print result\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66269e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
